{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 1\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7783.  7397.  4758. 10917.  1054.    91.]\n",
      "[+] Validation:\n",
      " [1861. 1873. 1271. 2707.  269.   19.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 30, 32)            288       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                7696      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,846\n",
      "Trainable params: 14,646\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 22s 703us/step - loss: 1.3755 - acc: 0.4183 - val_loss: 1.3063 - val_acc: 0.4547\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 1.2644 - acc: 0.4817 - val_loss: 1.2603 - val_acc: 0.4704\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2531 - acc: 0.4851 - val_loss: 1.2530 - val_acc: 0.4758\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 1.2424 - acc: 0.4904 - val_loss: 1.2468 - val_acc: 0.4796\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2357 - acc: 0.4928 - val_loss: 1.2404 - val_acc: 0.4809\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 1.2306 - acc: 0.4976 - val_loss: 1.2350 - val_acc: 0.4833\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 1.2233 - acc: 0.5018 - val_loss: 1.2316 - val_acc: 0.4906\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2201 - acc: 0.5064 - val_loss: 1.2253 - val_acc: 0.4918\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2133 - acc: 0.5101 - val_loss: 1.2289 - val_acc: 0.4933\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2102 - acc: 0.5133 - val_loss: 1.2241 - val_acc: 0.4914\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2051 - acc: 0.5137 - val_loss: 1.2193 - val_acc: 0.4974\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 1.2018 - acc: 0.5173 - val_loss: 1.2237 - val_acc: 0.4953\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 1.1958 - acc: 0.5200 - val_loss: 1.2187 - val_acc: 0.5015\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.1950 - acc: 0.5197 - val_loss: 1.2178 - val_acc: 0.5005\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.1909 - acc: 0.5208 - val_loss: 1.2173 - val_acc: 0.5040\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.1903 - acc: 0.5235 - val_loss: 1.2175 - val_acc: 0.4989\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1891 - acc: 0.5209 - val_loss: 1.2157 - val_acc: 0.5070\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1879 - acc: 0.5235 - val_loss: 1.2172 - val_acc: 0.5049\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1838 - acc: 0.5240 - val_loss: 1.2166 - val_acc: 0.5060\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1845 - acc: 0.5259 - val_loss: 1.2202 - val_acc: 0.5026\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1825 - acc: 0.5243 - val_loss: 1.2165 - val_acc: 0.5079\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1773 - acc: 0.5292 - val_loss: 1.2198 - val_acc: 0.5041\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1793 - acc: 0.5294 - val_loss: 1.2209 - val_acc: 0.5024\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1768 - acc: 0.5308 - val_loss: 1.2193 - val_acc: 0.5048\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1743 - acc: 0.5295 - val_loss: 1.2220 - val_acc: 0.5061\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1762 - acc: 0.5303 - val_loss: 1.2161 - val_acc: 0.5079\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1717 - acc: 0.5328 - val_loss: 1.2154 - val_acc: 0.5086\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1705 - acc: 0.5334 - val_loss: 1.2220 - val_acc: 0.5066\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1727 - acc: 0.5296 - val_loss: 1.2193 - val_acc: 0.5081\n",
      "Epoch 30/30\n",
      "30016/32000 [===========================>..] - ETA: 1s - loss: 1.1683 - acc: 0.5349"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 2\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7742.  7423.  4822. 10878.  1045.    90.]\n",
      "[+] Validation:\n",
      " [1902. 1847. 1207. 2746.  278.   20.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 29, 32)            544       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                7184      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,590\n",
      "Trainable params: 14,390\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 707us/step - loss: 1.3579 - acc: 0.4265 - val_loss: 1.2786 - val_acc: 0.4766\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2561 - acc: 0.4873 - val_loss: 1.2556 - val_acc: 0.4900\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2436 - acc: 0.4956 - val_loss: 1.2487 - val_acc: 0.4948\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2332 - acc: 0.5022 - val_loss: 1.2429 - val_acc: 0.4971\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2259 - acc: 0.5062 - val_loss: 1.2397 - val_acc: 0.4973\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2198 - acc: 0.5095 - val_loss: 1.2354 - val_acc: 0.5015\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2134 - acc: 0.5125 - val_loss: 1.2297 - val_acc: 0.5054\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2069 - acc: 0.5177 - val_loss: 1.2270 - val_acc: 0.5044\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2036 - acc: 0.5166 - val_loss: 1.2236 - val_acc: 0.5039\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1989 - acc: 0.5182 - val_loss: 1.2203 - val_acc: 0.5094\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1915 - acc: 0.5215 - val_loss: 1.2230 - val_acc: 0.5110\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1921 - acc: 0.5197 - val_loss: 1.2219 - val_acc: 0.5094\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1855 - acc: 0.5231 - val_loss: 1.2206 - val_acc: 0.5108\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1850 - acc: 0.5250 - val_loss: 1.2197 - val_acc: 0.5125\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1829 - acc: 0.5267 - val_loss: 1.2195 - val_acc: 0.5081\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1775 - acc: 0.5274 - val_loss: 1.2212 - val_acc: 0.5119\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1748 - acc: 0.5271 - val_loss: 1.2223 - val_acc: 0.5125\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1750 - acc: 0.5290 - val_loss: 1.2232 - val_acc: 0.5101\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1738 - acc: 0.5288 - val_loss: 1.2221 - val_acc: 0.5111\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1713 - acc: 0.5310 - val_loss: 1.2184 - val_acc: 0.5134\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1696 - acc: 0.5312 - val_loss: 1.2269 - val_acc: 0.5098\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1682 - acc: 0.5305 - val_loss: 1.2190 - val_acc: 0.5121\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1671 - acc: 0.5331 - val_loss: 1.2218 - val_acc: 0.5122\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1668 - acc: 0.5329 - val_loss: 1.2188 - val_acc: 0.5146\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1645 - acc: 0.5341 - val_loss: 1.2191 - val_acc: 0.5120\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1647 - acc: 0.5332 - val_loss: 1.2177 - val_acc: 0.5129\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1604 - acc: 0.5353 - val_loss: 1.2181 - val_acc: 0.5131\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1588 - acc: 0.5341 - val_loss: 1.2195 - val_acc: 0.5128\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1604 - acc: 0.5332 - val_loss: 1.2211 - val_acc: 0.5102\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1574 - acc: 0.5395 - val_loss: 1.2213 - val_acc: 0.5110\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 3\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7712.  7381.  4853. 10910.  1064.    80.]\n",
      "[+] Validation:\n",
      " [1932. 1889. 1176. 2714.  259.   30.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 28, 32)            800       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                7184      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,846\n",
      "Trainable params: 14,646\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 705us/step - loss: 1.4060 - acc: 0.4039 - val_loss: 1.3022 - val_acc: 0.4763\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 1.2781 - acc: 0.4737 - val_loss: 1.2724 - val_acc: 0.4821\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2608 - acc: 0.4842 - val_loss: 1.2623 - val_acc: 0.4836\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2486 - acc: 0.4900 - val_loss: 1.2511 - val_acc: 0.4934\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 1.2416 - acc: 0.4968 - val_loss: 1.2465 - val_acc: 0.4995\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2311 - acc: 0.5017 - val_loss: 1.2424 - val_acc: 0.5006\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2237 - acc: 0.5064 - val_loss: 1.2411 - val_acc: 0.5036\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2198 - acc: 0.5082 - val_loss: 1.2362 - val_acc: 0.5042\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2115 - acc: 0.5142 - val_loss: 1.2396 - val_acc: 0.5096\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2096 - acc: 0.5121 - val_loss: 1.2311 - val_acc: 0.5081\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2044 - acc: 0.5155 - val_loss: 1.2307 - val_acc: 0.5088\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2007 - acc: 0.5161 - val_loss: 1.2276 - val_acc: 0.5082\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.1991 - acc: 0.5165 - val_loss: 1.2288 - val_acc: 0.5075\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.1929 - acc: 0.5192 - val_loss: 1.2324 - val_acc: 0.5111\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1925 - acc: 0.5221 - val_loss: 1.2258 - val_acc: 0.5110\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.1883 - acc: 0.5224 - val_loss: 1.2280 - val_acc: 0.5095\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1860 - acc: 0.5243 - val_loss: 1.2277 - val_acc: 0.5111\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1840 - acc: 0.5227 - val_loss: 1.2227 - val_acc: 0.5144\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1819 - acc: 0.5266 - val_loss: 1.2229 - val_acc: 0.5089\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1810 - acc: 0.5261 - val_loss: 1.2242 - val_acc: 0.5094\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1778 - acc: 0.5280 - val_loss: 1.2222 - val_acc: 0.5129\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1769 - acc: 0.5274 - val_loss: 1.2271 - val_acc: 0.5141\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1744 - acc: 0.5282 - val_loss: 1.2207 - val_acc: 0.5131\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1725 - acc: 0.5299 - val_loss: 1.2221 - val_acc: 0.5149\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1711 - acc: 0.5321 - val_loss: 1.2259 - val_acc: 0.5079\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1718 - acc: 0.5306 - val_loss: 1.2196 - val_acc: 0.5145\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1676 - acc: 0.5307 - val_loss: 1.2184 - val_acc: 0.5106\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1665 - acc: 0.5310 - val_loss: 1.2228 - val_acc: 0.5118\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1655 - acc: 0.5321 - val_loss: 1.2220 - val_acc: 0.5140\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1644 - acc: 0.5332 - val_loss: 1.2179 - val_acc: 0.5131\n",
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7f3fb5883cc0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 702, in __del__\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/c_api_util.py\", line 31, in __init__\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 4\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7673.  7407.  4854. 10935.  1038.    93.]\n",
      "[+] Validation:\n",
      " [1971. 1863. 1175. 2689.  285.   17.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 27, 32)            1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                6672      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,590\n",
      "Trainable params: 14,390\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 706us/step - loss: 1.3777 - acc: 0.4186 - val_loss: 1.3000 - val_acc: 0.4645\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2604 - acc: 0.4897 - val_loss: 1.2570 - val_acc: 0.4861\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2459 - acc: 0.4967 - val_loss: 1.2548 - val_acc: 0.4890\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2355 - acc: 0.5031 - val_loss: 1.2464 - val_acc: 0.4966\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2292 - acc: 0.5093 - val_loss: 1.2384 - val_acc: 0.4971\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2199 - acc: 0.5101 - val_loss: 1.2386 - val_acc: 0.4985\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2123 - acc: 0.5151 - val_loss: 1.2304 - val_acc: 0.5009\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2091 - acc: 0.5155 - val_loss: 1.2272 - val_acc: 0.5041\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2040 - acc: 0.5172 - val_loss: 1.2252 - val_acc: 0.5055\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1998 - acc: 0.5197 - val_loss: 1.2253 - val_acc: 0.5044\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1964 - acc: 0.5200 - val_loss: 1.2216 - val_acc: 0.5071\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1914 - acc: 0.5223 - val_loss: 1.2207 - val_acc: 0.5065\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1892 - acc: 0.5228 - val_loss: 1.2238 - val_acc: 0.5062\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.1844 - acc: 0.5238 - val_loss: 1.2244 - val_acc: 0.5050\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1821 - acc: 0.5253 - val_loss: 1.2195 - val_acc: 0.5048\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1786 - acc: 0.5275 - val_loss: 1.2188 - val_acc: 0.5090\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1810 - acc: 0.5233 - val_loss: 1.2192 - val_acc: 0.5069\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1748 - acc: 0.5290 - val_loss: 1.2260 - val_acc: 0.5041\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1722 - acc: 0.5306 - val_loss: 1.2265 - val_acc: 0.5034\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1738 - acc: 0.5286 - val_loss: 1.2204 - val_acc: 0.5075\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1730 - acc: 0.5280 - val_loss: 1.2201 - val_acc: 0.5088\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1680 - acc: 0.5322 - val_loss: 1.2228 - val_acc: 0.5090\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1665 - acc: 0.5310 - val_loss: 1.2239 - val_acc: 0.5095\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1666 - acc: 0.5310 - val_loss: 1.2241 - val_acc: 0.5088\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1629 - acc: 0.5310 - val_loss: 1.2221 - val_acc: 0.5052\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1644 - acc: 0.5336 - val_loss: 1.2331 - val_acc: 0.5021\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1617 - acc: 0.5330 - val_loss: 1.2279 - val_acc: 0.5070\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1588 - acc: 0.5355 - val_loss: 1.2242 - val_acc: 0.5088\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1581 - acc: 0.5358 - val_loss: 1.2217 - val_acc: 0.5084\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1592 - acc: 0.5354 - val_loss: 1.2261 - val_acc: 0.5090\n",
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7fc36aa84cc0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 702, in __del__\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 5\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7739.  7454.  4841. 10841.  1031.    94.]\n",
      "[+] Validation:\n",
      " [1905. 1816. 1188. 2783.  292.   16.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 26, 32)            1312      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                6672      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,846\n",
      "Trainable params: 14,646\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 708us/step - loss: 1.4163 - acc: 0.4000 - val_loss: 1.2874 - val_acc: 0.4710\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2673 - acc: 0.4838 - val_loss: 1.2573 - val_acc: 0.4865\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2527 - acc: 0.4897 - val_loss: 1.2479 - val_acc: 0.4913\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2401 - acc: 0.4990 - val_loss: 1.2424 - val_acc: 0.4933\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2332 - acc: 0.4991 - val_loss: 1.2354 - val_acc: 0.5004\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2258 - acc: 0.5032 - val_loss: 1.2382 - val_acc: 0.4974\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2184 - acc: 0.5055 - val_loss: 1.2303 - val_acc: 0.5024\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2123 - acc: 0.5106 - val_loss: 1.2276 - val_acc: 0.5028\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2088 - acc: 0.5148 - val_loss: 1.2276 - val_acc: 0.5082\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2045 - acc: 0.5138 - val_loss: 1.2253 - val_acc: 0.5065\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2013 - acc: 0.5152 - val_loss: 1.2220 - val_acc: 0.5106\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 1.1948 - acc: 0.5191 - val_loss: 1.2215 - val_acc: 0.5051\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.1951 - acc: 0.5173 - val_loss: 1.2315 - val_acc: 0.5072\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1897 - acc: 0.5220 - val_loss: 1.2171 - val_acc: 0.5102\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.1882 - acc: 0.5228 - val_loss: 1.2221 - val_acc: 0.5096\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1873 - acc: 0.5229 - val_loss: 1.2250 - val_acc: 0.5032\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1824 - acc: 0.5261 - val_loss: 1.2276 - val_acc: 0.5100\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1796 - acc: 0.5239 - val_loss: 1.2189 - val_acc: 0.5076\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1812 - acc: 0.5251 - val_loss: 1.2193 - val_acc: 0.5048\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1794 - acc: 0.5269 - val_loss: 1.2176 - val_acc: 0.5126\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1771 - acc: 0.5289 - val_loss: 1.2201 - val_acc: 0.5082\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1738 - acc: 0.5287 - val_loss: 1.2202 - val_acc: 0.5120\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1741 - acc: 0.5302 - val_loss: 1.2144 - val_acc: 0.5162\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1720 - acc: 0.5316 - val_loss: 1.2228 - val_acc: 0.5118\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1701 - acc: 0.5306 - val_loss: 1.2153 - val_acc: 0.5148\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1661 - acc: 0.5325 - val_loss: 1.2144 - val_acc: 0.5160\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1679 - acc: 0.5313 - val_loss: 1.2165 - val_acc: 0.5175\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1651 - acc: 0.5329 - val_loss: 1.2153 - val_acc: 0.5166\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1653 - acc: 0.5315 - val_loss: 1.2215 - val_acc: 0.5119\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1658 - acc: 0.5307 - val_loss: 1.2134 - val_acc: 0.5156\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 6\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7714.  7386.  4877. 10902.  1040.    81.]\n",
      "[+] Validation:\n",
      " [1930. 1884. 1152. 2722.  283.   29.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 25, 32)            1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                6160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,590\n",
      "Trainable params: 14,390\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 709us/step - loss: 1.4440 - acc: 0.3606 - val_loss: 1.3513 - val_acc: 0.4340\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.3300 - acc: 0.4332 - val_loss: 1.3187 - val_acc: 0.4396\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.3088 - acc: 0.4538 - val_loss: 1.3001 - val_acc: 0.4770\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2833 - acc: 0.4779 - val_loss: 1.2767 - val_acc: 0.4851\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2640 - acc: 0.4875 - val_loss: 1.2631 - val_acc: 0.4936\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2500 - acc: 0.4978 - val_loss: 1.2566 - val_acc: 0.4978\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2367 - acc: 0.5035 - val_loss: 1.2546 - val_acc: 0.4966\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2314 - acc: 0.5045 - val_loss: 1.2465 - val_acc: 0.4968\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2262 - acc: 0.5065 - val_loss: 1.2410 - val_acc: 0.5000\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2173 - acc: 0.5086 - val_loss: 1.2376 - val_acc: 0.5028\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2114 - acc: 0.5128 - val_loss: 1.2316 - val_acc: 0.5031\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2079 - acc: 0.5135 - val_loss: 1.2394 - val_acc: 0.4993\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2021 - acc: 0.5152 - val_loss: 1.2297 - val_acc: 0.5050\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1995 - acc: 0.5191 - val_loss: 1.2400 - val_acc: 0.4994\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1950 - acc: 0.5198 - val_loss: 1.2359 - val_acc: 0.5035\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1920 - acc: 0.5195 - val_loss: 1.2432 - val_acc: 0.5024\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1904 - acc: 0.5204 - val_loss: 1.2295 - val_acc: 0.5054\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1859 - acc: 0.5237 - val_loss: 1.2309 - val_acc: 0.5080\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1831 - acc: 0.5264 - val_loss: 1.2414 - val_acc: 0.4946\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1809 - acc: 0.5250 - val_loss: 1.2275 - val_acc: 0.5054\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1794 - acc: 0.5275 - val_loss: 1.2283 - val_acc: 0.5081\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1780 - acc: 0.5286 - val_loss: 1.2293 - val_acc: 0.5065\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1738 - acc: 0.5305 - val_loss: 1.2351 - val_acc: 0.5019\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1712 - acc: 0.5290 - val_loss: 1.2309 - val_acc: 0.5062\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1671 - acc: 0.5321 - val_loss: 1.2404 - val_acc: 0.5034\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1677 - acc: 0.5309 - val_loss: 1.2320 - val_acc: 0.5094\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1652 - acc: 0.5322 - val_loss: 1.2342 - val_acc: 0.5062\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1643 - acc: 0.5324 - val_loss: 1.2287 - val_acc: 0.5060\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1652 - acc: 0.5302 - val_loss: 1.2361 - val_acc: 0.5044\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 689us/step - loss: 1.1608 - acc: 0.5339 - val_loss: 1.2344 - val_acc: 0.5012\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 7\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7677.  7474.  4827. 10888.  1042.    92.]\n",
      "[+] Validation:\n",
      " [1967. 1796. 1202. 2736.  281.   18.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 24, 32)            1824      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                6160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,846\n",
      "Trainable params: 14,646\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 708us/step - loss: 1.8069 - acc: 0.3492 - val_loss: 1.4648 - val_acc: 0.3420\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.4477 - acc: 0.3475 - val_loss: 1.4316 - val_acc: 0.3760\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.3723 - acc: 0.4131 - val_loss: 1.3358 - val_acc: 0.4395\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.3323 - acc: 0.4352 - val_loss: 1.3112 - val_acc: 0.4537\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.3081 - acc: 0.4522 - val_loss: 1.2935 - val_acc: 0.4704\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2929 - acc: 0.4647 - val_loss: 1.2770 - val_acc: 0.4798\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2745 - acc: 0.4813 - val_loss: 1.2654 - val_acc: 0.4888\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2581 - acc: 0.4902 - val_loss: 1.2498 - val_acc: 0.4881\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2492 - acc: 0.4943 - val_loss: 1.2448 - val_acc: 0.4953\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2379 - acc: 0.5014 - val_loss: 1.2552 - val_acc: 0.4856\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2285 - acc: 0.5047 - val_loss: 1.2345 - val_acc: 0.5010\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2247 - acc: 0.5025 - val_loss: 1.2304 - val_acc: 0.5005\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2178 - acc: 0.5083 - val_loss: 1.2293 - val_acc: 0.5050\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2172 - acc: 0.5099 - val_loss: 1.2253 - val_acc: 0.5079\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2098 - acc: 0.5110 - val_loss: 1.2260 - val_acc: 0.5055\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2072 - acc: 0.5141 - val_loss: 1.2316 - val_acc: 0.5060\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2010 - acc: 0.5162 - val_loss: 1.2288 - val_acc: 0.5055\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.2006 - acc: 0.5160 - val_loss: 1.2283 - val_acc: 0.5039\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1969 - acc: 0.5192 - val_loss: 1.2202 - val_acc: 0.5044\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1937 - acc: 0.5196 - val_loss: 1.2205 - val_acc: 0.5092\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1936 - acc: 0.5200 - val_loss: 1.2212 - val_acc: 0.5062\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1898 - acc: 0.5206 - val_loss: 1.2219 - val_acc: 0.5049\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1860 - acc: 0.5201 - val_loss: 1.2182 - val_acc: 0.5071\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1842 - acc: 0.5241 - val_loss: 1.2300 - val_acc: 0.5041\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1835 - acc: 0.5223 - val_loss: 1.2185 - val_acc: 0.5076\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1814 - acc: 0.5248 - val_loss: 1.2264 - val_acc: 0.5069\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1810 - acc: 0.5240 - val_loss: 1.2321 - val_acc: 0.5051\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1789 - acc: 0.5271 - val_loss: 1.2186 - val_acc: 0.5086\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1772 - acc: 0.5262 - val_loss: 1.2163 - val_acc: 0.5072\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1761 - acc: 0.5265 - val_loss: 1.2264 - val_acc: 0.5056\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 8\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7673.  7346.  4871. 10948.  1071.    91.]\n",
      "[+] Validation:\n",
      " [1971. 1924. 1158. 2676.  252.   19.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 23, 32)            2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5648      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,590\n",
      "Trainable params: 14,390\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 712us/step - loss: 1.4014 - acc: 0.4026 - val_loss: 1.3794 - val_acc: 0.4345\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2830 - acc: 0.4747 - val_loss: 1.2578 - val_acc: 0.4823\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.2646 - acc: 0.4850 - val_loss: 1.2471 - val_acc: 0.4879\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2564 - acc: 0.4897 - val_loss: 1.2426 - val_acc: 0.4894\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2480 - acc: 0.4958 - val_loss: 1.2377 - val_acc: 0.4955\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.2423 - acc: 0.4970 - val_loss: 1.2325 - val_acc: 0.4954\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2326 - acc: 0.5042 - val_loss: 1.2288 - val_acc: 0.4968\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2285 - acc: 0.5058 - val_loss: 1.2279 - val_acc: 0.4994\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2243 - acc: 0.5081 - val_loss: 1.2308 - val_acc: 0.4966\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2187 - acc: 0.5099 - val_loss: 1.2237 - val_acc: 0.5051\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2151 - acc: 0.5105 - val_loss: 1.2242 - val_acc: 0.5020\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2124 - acc: 0.5127 - val_loss: 1.2180 - val_acc: 0.5051\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2094 - acc: 0.5134 - val_loss: 1.2167 - val_acc: 0.5059\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2080 - acc: 0.5146 - val_loss: 1.2147 - val_acc: 0.5061\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2053 - acc: 0.5159 - val_loss: 1.2169 - val_acc: 0.5054\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2009 - acc: 0.5201 - val_loss: 1.2129 - val_acc: 0.5055\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1958 - acc: 0.5210 - val_loss: 1.2162 - val_acc: 0.5080\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1968 - acc: 0.5211 - val_loss: 1.2145 - val_acc: 0.5018\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1940 - acc: 0.5221 - val_loss: 1.2268 - val_acc: 0.5038\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1910 - acc: 0.5227 - val_loss: 1.2121 - val_acc: 0.5075\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1915 - acc: 0.5224 - val_loss: 1.2188 - val_acc: 0.5096\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1875 - acc: 0.5236 - val_loss: 1.2092 - val_acc: 0.5091\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1878 - acc: 0.5254 - val_loss: 1.2117 - val_acc: 0.5094\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1847 - acc: 0.5232 - val_loss: 1.2150 - val_acc: 0.5038\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1819 - acc: 0.5267 - val_loss: 1.2209 - val_acc: 0.5020\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1786 - acc: 0.5281 - val_loss: 1.2113 - val_acc: 0.5051\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1819 - acc: 0.5269 - val_loss: 1.2177 - val_acc: 0.5070\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1785 - acc: 0.5272 - val_loss: 1.2084 - val_acc: 0.5108\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1812 - acc: 0.5266 - val_loss: 1.2198 - val_acc: 0.5044\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1766 - acc: 0.5297 - val_loss: 1.2119 - val_acc: 0.5080\n",
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7f385cf44748>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 702, in __del__\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/c_api_util.py\", line 31, in __init__\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 9\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7732.  7385.  4785. 10945.  1064.    89.]\n",
      "[+] Validation:\n",
      " [1912. 1885. 1244. 2679.  259.   21.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 32)            2336      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5648      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,846\n",
      "Trainable params: 14,646\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 708us/step - loss: 1.3992 - acc: 0.4063 - val_loss: 1.3230 - val_acc: 0.4535\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2750 - acc: 0.4764 - val_loss: 1.2728 - val_acc: 0.4743\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 1.2639 - acc: 0.4831 - val_loss: 1.2590 - val_acc: 0.4855\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2527 - acc: 0.4850 - val_loss: 1.2536 - val_acc: 0.4915\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2453 - acc: 0.4897 - val_loss: 1.2477 - val_acc: 0.4891\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2373 - acc: 0.4924 - val_loss: 1.2456 - val_acc: 0.4914\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2293 - acc: 0.4947 - val_loss: 1.2406 - val_acc: 0.4948\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2229 - acc: 0.4988 - val_loss: 1.2340 - val_acc: 0.4969\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2145 - acc: 0.5054 - val_loss: 1.2295 - val_acc: 0.5011\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2076 - acc: 0.5100 - val_loss: 1.2264 - val_acc: 0.5031\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2029 - acc: 0.5152 - val_loss: 1.2264 - val_acc: 0.5031\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1973 - acc: 0.5162 - val_loss: 1.2253 - val_acc: 0.5091\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1929 - acc: 0.5186 - val_loss: 1.2227 - val_acc: 0.5046\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1901 - acc: 0.5212 - val_loss: 1.2240 - val_acc: 0.5048\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1886 - acc: 0.5205 - val_loss: 1.2223 - val_acc: 0.5036\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1840 - acc: 0.5241 - val_loss: 1.2235 - val_acc: 0.5070\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1812 - acc: 0.5249 - val_loss: 1.2193 - val_acc: 0.5100\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1822 - acc: 0.5246 - val_loss: 1.2212 - val_acc: 0.5074\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1775 - acc: 0.5266 - val_loss: 1.2301 - val_acc: 0.5045\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1769 - acc: 0.5276 - val_loss: 1.2195 - val_acc: 0.5056\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1738 - acc: 0.5283 - val_loss: 1.2213 - val_acc: 0.5076\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1729 - acc: 0.5306 - val_loss: 1.2225 - val_acc: 0.5060\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1723 - acc: 0.5290 - val_loss: 1.2244 - val_acc: 0.5056\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1706 - acc: 0.5316 - val_loss: 1.2246 - val_acc: 0.5041\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1691 - acc: 0.5279 - val_loss: 1.2220 - val_acc: 0.5101\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1662 - acc: 0.5329 - val_loss: 1.2253 - val_acc: 0.5071\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1652 - acc: 0.5300 - val_loss: 1.2234 - val_acc: 0.5062\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1615 - acc: 0.5337 - val_loss: 1.2266 - val_acc: 0.5096\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1614 - acc: 0.5349 - val_loss: 1.2244 - val_acc: 0.5058\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1582 - acc: 0.5353 - val_loss: 1.2225 - val_acc: 0.5078\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 10\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7689.  7439.  4778. 10939.  1071.    84.]\n",
      "[+] Validation:\n",
      " [1955. 1831. 1251. 2685.  252.   26.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 21, 32)            2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5136      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,590\n",
      "Trainable params: 14,390\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 706us/step - loss: 1.3877 - acc: 0.4166 - val_loss: 1.3071 - val_acc: 0.4546\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2753 - acc: 0.4763 - val_loss: 1.2686 - val_acc: 0.4718\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2569 - acc: 0.4853 - val_loss: 1.2543 - val_acc: 0.4816\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2469 - acc: 0.4915 - val_loss: 1.2492 - val_acc: 0.4841\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2374 - acc: 0.4972 - val_loss: 1.2429 - val_acc: 0.4870\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2282 - acc: 0.5004 - val_loss: 1.2386 - val_acc: 0.4938\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2231 - acc: 0.5052 - val_loss: 1.2404 - val_acc: 0.4945\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 1.2173 - acc: 0.5062 - val_loss: 1.2336 - val_acc: 0.4965\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.2105 - acc: 0.5108 - val_loss: 1.2323 - val_acc: 0.4985\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2069 - acc: 0.5125 - val_loss: 1.2285 - val_acc: 0.5045\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2028 - acc: 0.5137 - val_loss: 1.2288 - val_acc: 0.5016\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1999 - acc: 0.5133 - val_loss: 1.2318 - val_acc: 0.5036\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1966 - acc: 0.5155 - val_loss: 1.2220 - val_acc: 0.5106\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 679us/step - loss: 1.1947 - acc: 0.5207 - val_loss: 1.2227 - val_acc: 0.5078\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1894 - acc: 0.5198 - val_loss: 1.2244 - val_acc: 0.5045\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1854 - acc: 0.5240 - val_loss: 1.2244 - val_acc: 0.5081\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1833 - acc: 0.5253 - val_loss: 1.2259 - val_acc: 0.5072\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1834 - acc: 0.5231 - val_loss: 1.2198 - val_acc: 0.5109\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1772 - acc: 0.5289 - val_loss: 1.2229 - val_acc: 0.5085\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1769 - acc: 0.5251 - val_loss: 1.2232 - val_acc: 0.5085\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.1776 - acc: 0.5269 - val_loss: 1.2240 - val_acc: 0.5104\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1729 - acc: 0.5299 - val_loss: 1.2199 - val_acc: 0.5125\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1725 - acc: 0.5267 - val_loss: 1.2245 - val_acc: 0.5102\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1729 - acc: 0.5303 - val_loss: 1.2241 - val_acc: 0.5112\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1693 - acc: 0.5315 - val_loss: 1.2247 - val_acc: 0.5101\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1678 - acc: 0.5324 - val_loss: 1.2207 - val_acc: 0.5091\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1647 - acc: 0.5339 - val_loss: 1.2285 - val_acc: 0.5100\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.1632 - acc: 0.5310 - val_loss: 1.2255 - val_acc: 0.5099\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1634 - acc: 0.5321 - val_loss: 1.2219 - val_acc: 0.5084\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1642 - acc: 0.5340 - val_loss: 1.2273 - val_acc: 0.5065\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 11\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7735.  7379.  4809. 10923.  1065.    89.]\n",
      "[+] Validation:\n",
      " [1909. 1891. 1220. 2701.  258.   21.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 20, 32)            2848      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5136      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,846\n",
      "Trainable params: 14,646\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 711us/step - loss: 1.4310 - acc: 0.3822 - val_loss: 1.3187 - val_acc: 0.4607\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2985 - acc: 0.4650 - val_loss: 1.2816 - val_acc: 0.4788\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2803 - acc: 0.4743 - val_loss: 1.2737 - val_acc: 0.4753\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2654 - acc: 0.4792 - val_loss: 1.2579 - val_acc: 0.4856\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2516 - acc: 0.4863 - val_loss: 1.2493 - val_acc: 0.4898\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2414 - acc: 0.4918 - val_loss: 1.2408 - val_acc: 0.4963\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.2355 - acc: 0.4987 - val_loss: 1.2375 - val_acc: 0.4968\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.2274 - acc: 0.5008 - val_loss: 1.2332 - val_acc: 0.5060\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2206 - acc: 0.5039 - val_loss: 1.2342 - val_acc: 0.5029\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.2166 - acc: 0.5063 - val_loss: 1.2266 - val_acc: 0.5021\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.2105 - acc: 0.5122 - val_loss: 1.2278 - val_acc: 0.5070\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2082 - acc: 0.5113 - val_loss: 1.2228 - val_acc: 0.5098\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.2051 - acc: 0.5139 - val_loss: 1.2210 - val_acc: 0.5061\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2007 - acc: 0.5149 - val_loss: 1.2220 - val_acc: 0.5055\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1969 - acc: 0.5161 - val_loss: 1.2213 - val_acc: 0.5048\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1921 - acc: 0.5188 - val_loss: 1.2246 - val_acc: 0.5068\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1897 - acc: 0.5191 - val_loss: 1.2229 - val_acc: 0.5040\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1902 - acc: 0.5204 - val_loss: 1.2189 - val_acc: 0.5030\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1881 - acc: 0.5206 - val_loss: 1.2257 - val_acc: 0.5102\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1833 - acc: 0.5232 - val_loss: 1.2222 - val_acc: 0.5060\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 689us/step - loss: 1.1796 - acc: 0.5224 - val_loss: 1.2187 - val_acc: 0.5058\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1797 - acc: 0.5215 - val_loss: 1.2173 - val_acc: 0.5056\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1788 - acc: 0.5262 - val_loss: 1.2248 - val_acc: 0.5021\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1744 - acc: 0.5245 - val_loss: 1.2195 - val_acc: 0.5045\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1754 - acc: 0.5258 - val_loss: 1.2216 - val_acc: 0.5066\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 690us/step - loss: 1.1727 - acc: 0.5272 - val_loss: 1.2265 - val_acc: 0.5068\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1722 - acc: 0.5278 - val_loss: 1.2229 - val_acc: 0.5066\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1714 - acc: 0.5280 - val_loss: 1.2186 - val_acc: 0.5096\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1693 - acc: 0.5282 - val_loss: 1.2194 - val_acc: 0.5080\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1685 - acc: 0.5288 - val_loss: 1.2161 - val_acc: 0.5079\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "[!] Now performing test: 12\n",
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7708.  7427.  4788. 10944.  1045.    88.]\n",
      "[+] Validation:\n",
      " [1936. 1843. 1241. 2680.  278.   22.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6101200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 19, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4624      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,115,590\n",
      "Trainable params: 14,390\n",
      "Non-trainable params: 6,101,200\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 23s 710us/step - loss: 1.4199 - acc: 0.3891 - val_loss: 1.3059 - val_acc: 0.4745\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2859 - acc: 0.4714 - val_loss: 1.2811 - val_acc: 0.4781\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2689 - acc: 0.4793 - val_loss: 1.2689 - val_acc: 0.4848\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.2578 - acc: 0.4830 - val_loss: 1.2665 - val_acc: 0.4854\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 1.2460 - acc: 0.4903 - val_loss: 1.2647 - val_acc: 0.4814\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2390 - acc: 0.4925 - val_loss: 1.2538 - val_acc: 0.4904\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.2288 - acc: 0.4984 - val_loss: 1.2542 - val_acc: 0.4938\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 22s 682us/step - loss: 1.2245 - acc: 0.5006 - val_loss: 1.2479 - val_acc: 0.4956\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2181 - acc: 0.5033 - val_loss: 1.2459 - val_acc: 0.4983\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2119 - acc: 0.5076 - val_loss: 1.2464 - val_acc: 0.5029\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.2078 - acc: 0.5099 - val_loss: 1.2431 - val_acc: 0.5032\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.2028 - acc: 0.5117 - val_loss: 1.2404 - val_acc: 0.5066\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1985 - acc: 0.5136 - val_loss: 1.2410 - val_acc: 0.5056\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1971 - acc: 0.5152 - val_loss: 1.2444 - val_acc: 0.5009\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1912 - acc: 0.5186 - val_loss: 1.2361 - val_acc: 0.5068\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 1.1890 - acc: 0.5193 - val_loss: 1.2360 - val_acc: 0.5066\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1878 - acc: 0.5198 - val_loss: 1.2453 - val_acc: 0.5066\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1824 - acc: 0.5236 - val_loss: 1.2388 - val_acc: 0.5046\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1805 - acc: 0.5223 - val_loss: 1.2364 - val_acc: 0.5051\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1806 - acc: 0.5219 - val_loss: 1.2414 - val_acc: 0.5091\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1767 - acc: 0.5250 - val_loss: 1.2458 - val_acc: 0.5065\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1734 - acc: 0.5277 - val_loss: 1.2376 - val_acc: 0.5111\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 22s 688us/step - loss: 1.1707 - acc: 0.5287 - val_loss: 1.2415 - val_acc: 0.5096\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 22s 686us/step - loss: 1.1702 - acc: 0.5264 - val_loss: 1.2439 - val_acc: 0.5048\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 22s 687us/step - loss: 1.1702 - acc: 0.5279 - val_loss: 1.2376 - val_acc: 0.5098\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1690 - acc: 0.5306 - val_loss: 1.2368 - val_acc: 0.5122\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1660 - acc: 0.5302 - val_loss: 1.2480 - val_acc: 0.5051\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.1638 - acc: 0.5312 - val_loss: 1.2339 - val_acc: 0.5120\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 22s 683us/step - loss: 1.1625 - acc: 0.5344 - val_loss: 1.2322 - val_acc: 0.5141\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 1.1628 - acc: 0.5297 - val_loss: 1.2328 - val_acc: 0.5132\n"
     ]
    }
   ],
   "source": [
    "!python3 run_filter_test.py 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
